{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autocompleter \n",
    "autocompl = autocompleter.Autocompleter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load json file...\n",
      "(22264, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((22264, 3), Index(['IsFromCustomer', 'Text', 'index'], dtype='object'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = autocompl.import_json(\"sample_conversations.json\")\n",
    "df.shape, df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file contains 22K conversations between a customer and a representative.\n",
    "For the purpose of this project, we are only interested in completing the threads of the representative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IsFromCustomer</th>\n",
       "      <th>Text</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>Hi! I placed an order on your website and I ca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>I think I used my email address to log in.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>My battery exploded!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>It's on fire, it's melting the carpet!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>What should I do!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IsFromCustomer                                               Text  index\n",
       "0            True  Hi! I placed an order on your website and I ca...      0\n",
       "1            True         I think I used my email address to log in.      0\n",
       "2            True                               My battery exploded!      1\n",
       "3            True             It's on fire, it's melting the carpet!      1\n",
       "4            True                                  What should I do!      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Selection and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is going to separate the threads from the customer and the representative, separate the sentenses based on the punctuation (we will keep the punctuation), the final text will be cleaned up with some light regex and only the sentense larger than 1 word will be kept."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, since the representative has the tendency to ask the same question over and over again, the autocomplete is extremely useful by suggesting a complete sentense. In our case, we will count the number of occurence of the same sentense so we can use it as a feature later on and delete the duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select representative threads...\n",
      "split sentenses on punctuation...\n",
      "Text Cleaning using simple regex...\n",
      "calculate nb words of sentenses...\n",
      "count occurence of sentenses...\n",
      "remove duplicates (keep last)...\n",
      "(8560, 5)\n",
      "(8560, 5)\n",
      "Index(['IsFromCustomer', 'Text', 'index', 'nb_words', 'Counts'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "new_df = autocompl.process_data(df)\n",
    "new_df.shape, new_df.columns\n",
    "print(new_df.shape)\n",
    "print(new_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and TFIDF matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A matrice of similarity is calculated based on the frequency of all the words in the data using tfidfvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf_matrice  (8560, 252)\n",
      "TF-IDF matrix and model successfully created.\n",
      "TF-IDF matrix and vectorizer successfully created.\n",
      "Index(['IsFromCustomer', 'Text', 'index', 'nb_words', 'Counts'], dtype='object')\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model_tf, tfidf_matrice = autocompl.calc_matrice(new_df)\n",
    "    print(\"TF-IDF matrix and model successfully created.\")\n",
    "except AttributeError as e:\n",
    "    print(f\"Error in calc_matrice: {e}\")\n",
    "    raise\n",
    "\n",
    "# No need to call calc_matrice again here\n",
    "print(\"TF-IDF matrix and vectorizer successfully created.\")\n",
    "print(new_df.columns)\n",
    "# Ensure that the TF-IDF matrix is in the correct format\n",
    "print(type(tfidf_matrice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      1.00      1.00      1712\n",
      "\n",
      "    accuracy                           1.00      1712\n",
      "   macro avg       1.00      1.00      1.00      1712\n",
      "weighted avg       1.00      1.00      1.00      1712\n",
      "\n",
      "Accuracy: 1.0\n",
      "Cross-Validation Scores: [1. 1. 1. 1. 1.]\n",
      "Mean CV Score: 1.0\n",
      "IsFromCustomer\n",
      "False    8560\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X = tfidf_matrice\n",
    "y = new_df['IsFromCustomer']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "rf_y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Output the classification report\n",
    "print(\"Random Forest Classifier:\")\n",
    "print(classification_report(y_test, rf_y_pred))\n",
    "\n",
    "# Output the accuracy\n",
    "rf_accuracy = accuracy_score(y_test, rf_y_pred)\n",
    "print(f'Accuracy: {rf_accuracy}')\n",
    "\n",
    "\n",
    "cross_val_scores = cross_val_score(rf_model, X, y, cv=5)\n",
    "print(\"Cross-Validation Scores:\", cross_val_scores)\n",
    "print(\"Mean CV Score:\", cross_val_scores.mean())\n",
    "print(new_df['IsFromCustomer'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the autocomplete is calculating the similarity between the sentense in the data and the prefix of the sentense written by the representative. As a weight feature, we chose to reorder using the frequency of the most common similar sentense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "examples of auto completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is your     \n",
      " \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['What is your zip code?', 'What is your username?', 'What is your address?']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix = 'What is your'\n",
    "\n",
    "print(prefix,\"    \\n \")\n",
    "\n",
    "autocompl.generate_completions(prefix, new_df, model_tf,tfidf_matrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can      \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Yes I can', 'I can imagine', 'I can include a dust cleaner']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix = 'How can'\n",
    "print(prefix,\"     \")\n",
    "autocompl.generate_completions(prefix, new_df, model_tf,tfidf_matrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let me      \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Let me research this',\n",
       " 'Let me investigate',\n",
       " 'Let me investigate this quickly']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix = 'Let me'\n",
    "print(prefix,\"     \")\n",
    "autocompl.generate_completions(prefix, new_df, model_tf,tfidf_matrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when was      \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['When was the last time you changed your password?',\n",
       " 'Please use code 20% when ordering',\n",
       " 'Use the code 20% when ordering']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix = 'when was'\n",
    "print(prefix,\"     \")\n",
    "autocompl.generate_completions(prefix, new_df, model_tf,tfidf_matrice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, without any uppercase and just with the important words..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when time password      \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['When was the last time you changed your password?',\n",
       " 'When was the last time you changed your wi-fi password?',\n",
       " 'When you select you password?']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix = 'when time password'\n",
    "print(prefix,\"     \")\n",
    "autocompl.generate_completions(prefix, new_df, model_tf,tfidf_matrice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online Sources for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gist.github.com/jlln/338b4b0b55bd6984f883 modified to keep punctuation\n",
    "# kaggle google store competition for json read\n",
    "# https://www.kaggle.com/hamishdickson/weighted-word-autocomplete-using-star-wars-dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
